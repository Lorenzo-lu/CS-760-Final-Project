{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aTyT_XmmBvKG"
   },
   "outputs": [],
   "source": [
    "import sys;\n",
    "import torch;\n",
    "import torch.nn as nn;\n",
    "import torchtext.data as ttd;\n",
    "from torchtext.vocab import GloVe;\n",
    "\n",
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt;\n",
    "import pandas as pd;\n",
    "pd.options.mode.chained_assignment = None; ## avoid warning\n",
    "#from datetime import datetime;\n",
    "import time;\n",
    "## time.process_time() to record the time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1588369053503,
     "user": {
      "displayName": "YIZHOU LU",
      "photoUrl": "",
      "userId": "12883021123371670841"
     },
     "user_tz": 300
    },
    "id": "qjgtLbZHDRPi",
    "outputId": "4111acf8-8da4-446a-c0d9-434ab4db7fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import os;\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive');\n",
    "path = \"/content/drive/My Drive\";\n",
    "os.chdir(path);\n",
    "os.listdir(path);\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ud_XSDW-BvKK"
   },
   "source": [
    "## step 1 data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3365,
     "status": "ok",
     "timestamp": 1588369056581,
     "user": {
      "displayName": "YIZHOU LU",
      "photoUrl": "",
      "userId": "12883021123371670841"
     },
     "user_tz": 300
    },
    "id": "iVb8LEZRBvKL",
    "outputId": "e6581c69-5665-4494-8111-a3bec613de25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yizhou said 欲速则不达，施主稍安勿躁: | ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒ | 100.0% (^_^)/ Done!"
     ]
    }
   ],
   "source": [
    "def Process_bar(ratio, comments = False, overwrite = True, length = 50):\n",
    "    bar = 'Yizhou said 欲速则不达，施主稍安勿躁: | ';\n",
    "    i = 0;\n",
    "    while i < ratio * length:\n",
    "        bar += '▒';\n",
    "        i += 1;\n",
    "    while i < length:\n",
    "        bar += '░';\n",
    "        i += 1;\n",
    "    \n",
    "    bar += (' | %s%%'%(int(ratio*1000)/10));\n",
    "    if ratio == 1:\n",
    "        bar += ' (^_^)/ Done!'\n",
    "    if comments != False:\n",
    "        bar += ('\\n' + str(comments));\n",
    "    if overwrite == True:\n",
    "        print('\\r', end='');\n",
    "    else:\n",
    "        print('\\n',end = '');\n",
    "    print(bar, end='');\n",
    "    sys.stdout.flush();\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def Twitter_text_clean(text):\n",
    "    \n",
    "    #print(text)\n",
    "    i = 1;\n",
    "    #while text[i-1:i+1] != ': ':\n",
    "    while i < len(text):\n",
    "        if text[i-1:i+1] == ': ':\n",
    "            break;\n",
    "        i += 1;\n",
    "        \n",
    "    if i >= len(text):\n",
    "        return text;\n",
    "    else:   \n",
    "        return text[i+1:];\n",
    "\n",
    "#!wget https://drive.google.com/open?id=1l59-HAyiqb6jcrE7ks-UWAaDn97L7p3l\n",
    "\n",
    "df = pd.read_csv('first-gop-debate-twitter-sentiment/Sentiment.csv');\n",
    "#df = pd.read_csv('/content/drive/My Drive/Code Colab/Sentiment analysis/CNN/first-gop-debate-twitter-sentiment/Sentiment.csv');\n",
    "\n",
    "df['binary_labels'] = df['sentiment'].map({'Neutral': 0, 'Negative':2, 'Positive':1});\n",
    "df2 = df[['binary_labels','text']];\n",
    "\n",
    "print_out = int(len(df2['text'])/100);\n",
    "#print_out = 1;\n",
    "for i in range(len(df2['text'])):\n",
    "    \n",
    "    if i%print_out == 0:\n",
    "        ratio = (i+1)/len(df2['text']);\n",
    "        Process_bar(ratio);\n",
    "    \n",
    "    df2['text'][i] = Twitter_text_clean(df['text'][i]);\n",
    "Process_bar(1);\n",
    "df2.to_csv('twitter.csv', index = False);\n",
    "\n",
    "## classes is 2 now!\n",
    "K_class = 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "viNQzF5XFcxS"
   },
   "source": [
    "## Step 2 To Cuda & +ttd\n",
    "Preparaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3829,
     "status": "ok",
     "timestamp": 1588369057197,
     "user": {
      "displayName": "YIZHOU LU",
      "photoUrl": "",
      "userId": "12883021123371670841"
     },
     "user_tz": 300
    },
    "id": "gH6xGxY9BvKO",
    "outputId": "ee53dd59-c5ea-49ff-fcc6-0c76878736ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20044\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "TEXT = ttd.Field(\n",
    "    sequential = True,\n",
    "    batch_first = True,\n",
    "    lower = True,\n",
    "    #tokenize = 'spacy',\n",
    "    pad_first = True\n",
    ")\n",
    "LABEL = ttd.Field(sequential = False, use_vocab = False, is_target = True);\n",
    "dataset = ttd.TabularDataset(path = 'twitter.csv', format = 'csv',\n",
    "                             skip_header = True,\n",
    "                             fields = [('label', LABEL),('data', TEXT)] \n",
    "                             ## it will generate an obj dattset.example.data\n",
    "                             ## and an obj dattset.example.label\n",
    "                             );\n",
    "\n",
    "train_dataset, test_dataset = dataset.split(0.7);## default 0.7 here\n",
    "TEXT.build_vocab(train_dataset);\n",
    "vocab = TEXT.vocab;\n",
    "print(len(vocab));\n",
    "#vocab.stoi\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "print(device);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FagSvnEFrKL"
   },
   "source": [
    "## split training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6317,
     "status": "ok",
     "timestamp": 1588369059840,
     "user": {
      "displayName": "YIZHOU LU",
      "photoUrl": "",
      "userId": "12883021123371670841"
     },
     "user_tz": 300
    },
    "id": "8xEAlg1JBvKR",
    "outputId": "ae3c0c4a-d732-4baf-9b7d-c3672a797ff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9710\n",
      "4161\n",
      "0 torch.Size([32, 23])\n",
      "1 torch.Size([32, 25])\n",
      "2 torch.Size([32, 23])\n",
      "3 torch.Size([32, 26])\n",
      "4 torch.Size([32, 25])\n",
      "10 torch.Size([32, 27])\n",
      "20 torch.Size([32, 24])\n",
      "30 torch.Size([32, 23])\n",
      "40 torch.Size([32, 23])\n",
      "304\n",
      "0 torch.Size([1000, 12])\n",
      "1 torch.Size([1000, 16])\n",
      "2 torch.Size([1000, 19])\n",
      "3 torch.Size([1000, 23])\n",
      "4 torch.Size([161, 29])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter = ttd.Iterator.splits(\n",
    "    (train_dataset, test_dataset), \n",
    "    sort_key = lambda x: len(x.data), ## x is this object\n",
    "    batch_sizes = (32,1000),\n",
    "    device = device\n",
    "    );\n",
    "print(len(train_dataset));\n",
    "print(len(test_dataset))\n",
    "printlist = [0,1,2,3,4,10,20,30,40];\n",
    "ind = 0;\n",
    "for inputs, targets in train_iter:\n",
    "    #T_indicator = torch.zeros(len(labels), 2).scatter_(1, labels, 1)\n",
    "    #print(inputs,'\\n',targets);\n",
    "    #break;\n",
    "    if ind in printlist:\n",
    "        print(ind, inputs.shape);\n",
    "        #print(targets)\n",
    "        #print(T_indicator); \n",
    "    ind += 1;\n",
    "print(ind)\n",
    "\n",
    "ind = 0;\n",
    "for inputs, targets in test_iter:\n",
    "    #print(inputs,'\\n',targets);\n",
    "    #break;\n",
    "    if ind in printlist:\n",
    "        print(ind, inputs.shape);\n",
    "    ind += 1;\n",
    "print(ind);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AC1YFTXJWRfy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_29DAXSBvKU"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F;\n",
    "'''\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_vocab, embed_dim, n_outputs):\n",
    "        super(CNN,self).__init__();\n",
    "        self.V = n_vocab;\n",
    "        self.D = embed_dim;\n",
    "        self.K = n_outputs;\n",
    "\n",
    "        ## dropout\n",
    "        self.dropout = nn.Dropout(p = 0.5);\n",
    "\n",
    "        ##layers implement\n",
    "        self.embed = nn.Embedding(self.V, self.D);\n",
    "        ## embed layer output is [N T D];\n",
    "\n",
    "        self.conv1 = nn.Conv1d(self.D, 32, 3, padding=1);\n",
    "        ## conv layer 1 output is [N T M];\n",
    "\n",
    "        self.pool1 = nn.MaxPool1d(2);\n",
    "        ## max pooling layer 1 output is [N T2 M]\n",
    "\n",
    "        self.conv2 = nn.Conv1d(32, 64, 3, padding = 1);\n",
    "        ## conv layer 2 output is  [N T2 M2]\n",
    "\n",
    "        self.pool2 = nn.MaxPool1d(2);\n",
    "        ## max pooling layer 2 output is [N T3 M2];\n",
    "\n",
    "        self.conv3 = nn.Conv1d(64, 128,3, padding = 1);\n",
    "        ## conv layer 3 output is [N T3 M3]\n",
    "\n",
    "        # flattern / global max pool later \n",
    "        ## output [N M3]\n",
    "        self.fc = nn.Linear(128, self.K);\n",
    "        \n",
    "\n",
    "'''\n",
    "        #in Torch, features come first\n",
    "        #in TF/ NLP, features come last\n",
    "        \n",
    "        #So Before and After Convolution layer, we HAVE to reshape! \n",
    "'''\n",
    "    def forward(self,X):\n",
    "        ## input is [N T]\n",
    "        # embed layer\n",
    "        out = self.embed(X); ## output is [N T D]\n",
    "\n",
    "        out = out.permute(0,2,1); ## out is [N D T], feature first\n",
    "        out = self.conv1(out); ## out is [N M T]\n",
    "        out = F.relu(out); ## [N M T]\n",
    "        out = self.dropout(out);\n",
    "        out = self.pool1(out); ## out is [N M T2];\n",
    "\n",
    "        out = self.conv2(out); ## out is [N M2 T2]\n",
    "        out = F.relu(out); ## [N M2 T2]\n",
    "        out = self.dropout(out);\n",
    "        out = self.pool2(out); ## out is [N M2 T3];\n",
    "\n",
    "        out = self.conv3(out); ## [N M3 T3];\n",
    "        out = self.dropout(out);\n",
    "\n",
    "        out = out.permute(0,2,1); ## [N T3 M3];\n",
    "        out,_ = torch.max(out,1); ## [N M3]; Global Max pool\n",
    "        \n",
    "        out = F.relu(out);\n",
    "\n",
    "        ## final dense layer\n",
    "        out = self.fc(out);\n",
    "        #out = F.log_softmax(out,dim=1)\n",
    "        return out;\n",
    "''';\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_vocab, embed_dim,  n_outputs):\n",
    "        super(CNN,self).__init__();\n",
    "\n",
    "        self.V = n_vocab;\n",
    "        self.D = embed_dim;\n",
    "        \n",
    "        self.K = n_outputs;\n",
    "        ## dropout\n",
    "        #self.dropout = nn.Dropout(p = 0.25);\n",
    "\n",
    "        ## before this mode is sent to GPU, we have to define its dimensions first\n",
    "        ## so you cannot using call any parameters like self.V self.D in this forward \n",
    "        ##function\n",
    "        self.embed = nn.Embedding(self.V, self.D); \n",
    "\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv1d(self.D, 32, 3, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(32, 64, 3, padding = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(64, 128,3, padding = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            #nn.Linear(128, self.K1);\n",
    "        );\n",
    "\n",
    "        self.fully_connect = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),            \n",
    "\n",
    "            nn.Linear(32, self.K),\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "\n",
    "\n",
    "    def forward(self,X):\n",
    "        #out = self.embed(X); ## output is [N T D]\n",
    "        out = self.embed(X);\n",
    "\n",
    "        out = out.permute(0,2,1); ## out is [N D T], feature first\n",
    "        out = self.conv_layer(out);\n",
    "        out = out.permute(0,2,1); ## [N T3 M3];\n",
    "\n",
    "        out,_ = torch.max(out,1); ## [N M3]; Global Max pool\n",
    "        out = self.fully_connect(out);\n",
    "        return out;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HakdL5EhBvKX"
   },
   "outputs": [],
   "source": [
    "model = CNN(len(vocab), 50, K_class);\n",
    "model.to(device);\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(); ## Python can even return a function\n",
    "#criterion = nn.CrossEntropyLoss();\n",
    "#optimizer = torch.optim.Adam(model.parameters(),lr=1e-3);\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-3, momentum = 0.5);\n",
    "\n",
    "def batch_gd(model, criterion, optimizer, train_iter, test_iter, epochs, print_epoch = 20):\n",
    "    start = time.time();\n",
    "    \n",
    "    train_losses = np.zeros(epochs);\n",
    "    test_losses = np.zeros(epochs);\n",
    "\n",
    "    for it in range(epochs):\n",
    "        #if it%print_epoch  == 0:\n",
    "            #now = time.process_time();\n",
    "        \n",
    "        train_loss = [];\n",
    "        \n",
    "        for inputs, targets in train_iter:\n",
    "            #targets = targets.view(-1,1).float();\n",
    "            #targets = targets.view(-1,1).int();\n",
    "\n",
    "            targets = torch.nn.functional.one_hot(targets, K_class).float();   \n",
    "\n",
    "            ## move data to GPU\n",
    "            inputs, targets  =  inputs.to(device), targets.to(device);\n",
    "\n",
    "            ## zero the parameter gradient\n",
    "            optimizer.zero_grad();\n",
    "\n",
    "            ## forward pass\n",
    "            outputs = model(inputs);\n",
    "\n",
    "            loss = criterion(outputs, targets);\n",
    "\n",
    "            ## back probagation\n",
    "            loss.backward();\n",
    "            optimizer.step();\n",
    "            train_loss.append(loss.item());\n",
    "\n",
    "        train_loss = np.mean(train_loss);\n",
    "\n",
    "        test_loss = [];\n",
    "        for inputs, targets in test_iter:\n",
    "            #targets = targets.view(-1,1).float();\n",
    "            targets = torch.nn.functional.one_hot(targets, K_class).float();\n",
    "            ## move data to GPU\n",
    "            inputs, targets  =  inputs.to(device), targets.to(device);\n",
    "\n",
    "            ## zero the parameter gradient\n",
    "            optimizer.zero_grad();\n",
    "\n",
    "            ## forward pass,  no need to back\n",
    "            outputs = model(inputs);\n",
    "            loss = criterion(outputs, targets);\n",
    "            test_loss.append(loss.item());\n",
    "        \n",
    "        test_loss = np.mean(test_loss);\n",
    "\n",
    "        train_losses[it] = train_loss;\n",
    "        test_losses[it] = test_loss;\n",
    "\n",
    "        if it%print_epoch  == 0:\n",
    "            dt = time.time() - start;\n",
    "            nn_comments = \"Epoch (%d / %d)...Train_Loss: %.3e...Test_loss: %.3e...Duration: %.3e sec\"\\\n",
    "                %(it+1, epochs, train_loss, test_loss, dt);\n",
    "\n",
    "            Process_bar((it+1)/epochs*1.0, comments=nn_comments, overwrite = False);\n",
    "    Process_bar(1.0, comments='Done!', overwrite = False);\n",
    "    \n",
    "    return train_losses, test_losses;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 42031,
     "status": "ok",
     "timestamp": 1588369096192,
     "user": {
      "displayName": "YIZHOU LU",
      "photoUrl": "",
      "userId": "12883021123371670841"
     },
     "user_tz": 300
    },
    "id": "pCJJ-csbBvKa",
    "outputId": "f6e6ccf0-5836-48c9-9328-5af4163597b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Yizhou said 欲速则不达，施主稍安勿躁: | ▒▒░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ | 3.3%\n",
      "Epoch (1 / 30)...Train_Loss: 7.544e-01...Test_loss: 7.539e-01...Duration: 1.295e+00 sec\n",
      "Yizhou said 欲速则不达，施主稍安勿躁: | ▒▒▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ | 13.3%\n",
      "Epoch (4 / 30)...Train_Loss: 7.480e-01...Test_loss: 7.476e-01...Duration: 4.880e+00 sec\n",
      "Yizhou said 欲速则不达，施主稍安勿躁: | ▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ | 23.3%\n",
      "Epoch (7 / 30)...Train_Loss: 7.395e-01...Test_loss: 7.392e-01...Duration: 8.394e+00 sec\n",
      "Yizhou said 欲速则不达，施主稍安勿躁: | ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ | 33.3%\n",
      "Epoch (10 / 30)...Train_Loss: 7.279e-01...Test_loss: 7.279e-01...Duration: 1.211e+01 sec\n",
      "Yizhou said 欲速则不达，施主稍安勿躁: | ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░░░░░░░░ | 43.3%\n",
      "Epoch (13 / 30)...Train_Loss: 7.139e-01...Test_loss: 7.162e-01...Duration: 1.568e+01 sec\n",
      "Yizhou said 欲速则不达，施主稍安勿躁: | ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░░░ | 53.3%\n",
      "Epoch (16 / 30)...Train_Loss: 7.044e-01...Test_loss: 7.079e-01...Duration: 1.937e+01 sec\n",
      "Yizhou said 欲速则不达，施主稍安勿躁: | ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░░░░░░░░░░░░░ | 63.3%\n",
      "Epoch (19 / 30)...Train_Loss: 7.001e-01...Test_loss: 7.046e-01...Duration: 2.295e+01 sec\n",
      "Yizhou said 欲速则不达，施主稍安勿躁: | ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░░░░░░░░ | 73.3%\n",
      "Epoch (22 / 30)...Train_Loss: 6.978e-01...Test_loss: 7.026e-01...Duration: 2.663e+01 sec\n",
      "Yizhou said 欲速则不达，施主稍安勿躁: | ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░░░ | 83.3%\n",
      "Epoch (25 / 30)...Train_Loss: 6.973e-01...Test_loss: 7.017e-01...Duration: 3.020e+01 sec\n",
      "Yizhou said 欲速则不达，施主稍安勿躁: | ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░ | 93.3%\n",
      "Epoch (28 / 30)...Train_Loss: 6.966e-01...Test_loss: 7.010e-01...Duration: 3.375e+01 sec\n",
      "Yizhou said 欲速则不达，施主稍安勿躁: | ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒ | 100.0% (^_^)/ Done!\n",
      "Done!"
     ]
    }
   ],
   "source": [
    "CNN_epochs = 30;\n",
    "train_losses, test_losses = batch_gd(model, criterion, optimizer, train_iter, test_iter, CNN_epochs,3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41874,
     "status": "ok",
     "timestamp": 1588369096193,
     "user": {
      "displayName": "YIZHOU LU",
      "photoUrl": "",
      "userId": "12883021123371670841"
     },
     "user_tz": 300
    },
    "id": "f3pwahebBvKe",
    "outputId": "533bb17f-6342-467b-f41c-5ed27c71d0b8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure();\n",
    "plt.step(range(len(train_losses)),train_losses, c = 'r', label = 'Train_Error');\n",
    "plt.step(range(len(test_losses)),test_losses, c = 'b', label  = 'Test_Error');\n",
    "plt.legend();\n",
    "plt.xlabel('Epochs');\n",
    "plt.ylabel('Loss');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 42408,
     "status": "ok",
     "timestamp": 1588369096884,
     "user": {
      "displayName": "YIZHOU LU",
      "photoUrl": "",
      "userId": "12883021123371670841"
     },
     "user_tz": 300
    },
    "id": "ly58CjdrBvKg",
    "outputId": "04f710e3-337e-4160-d305-61e3f6fcd30a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 6.142e-01 \n",
      "Testing Accuracy = 6.078e-01\n"
     ]
    }
   ],
   "source": [
    "## Accuracy:\n",
    "n_correct = 0.0;\n",
    "n_total = 0.0;\n",
    "\n",
    "for inputs, targets in train_iter:\n",
    "    #targets = targets.view(-1,1).float();\n",
    "    targets = torch.nn.functional.one_hot(targets, K_class).float(); \n",
    "    outputs = model(inputs);\n",
    "    prediction = (torch.argmax(outputs, dim=1));\n",
    "\n",
    "    n_total += targets.shape[0];\n",
    "    n_correct += (torch.argmax(targets, dim=1) == prediction).sum().item();\n",
    "\n",
    "train_acc = n_correct/n_total;\n",
    "\n",
    "n_correct = 0.0;\n",
    "n_total = 0.0;\n",
    "for inputs, targets in test_iter:\n",
    "    #targets = targets.view(-1,1).float();\n",
    "    targets = torch.nn.functional.one_hot(targets, K_class).float(); \n",
    "    outputs = model(inputs);\n",
    "    #prediction = (outputs > 0);\n",
    "    prediction = (torch.argmax(outputs, dim=1));\n",
    "\n",
    "    n_total += targets.shape[0];\n",
    "    n_correct += (torch.argmax(targets, dim=1) == prediction).sum().item();\n",
    "\n",
    "test_acc = n_correct/n_total;\n",
    "\n",
    "print(\"Training Accuracy = %.3e \\nTesting Accuracy = %.3e\" %(train_acc,\n",
    "                                                             test_acc));\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rft9fGqjBvKp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zktC9_u6ZElq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4vRA7rN-Zax4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNN sentiment test1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
